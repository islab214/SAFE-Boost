import os, shutil
import subprocess
import time
import argparse

# =========================================
# Helper to clear OS caches
# =========================================
def cleanup_caches():
    subprocess.run(["sudo", "sh", "-c", "echo 3 > /proc/sys/vm/drop_caches"], check=False)
    print("â–¶ í˜ì´ì§€ ìºì‹œ ë¹„ìš°ê¸° ì™„ë£Œ")

# =========================================
# Parse CLI arguments
# =========================================
parser = argparse.ArgumentParser(
    description="Run binning + HE training/inf experiments with manual parameter combos"
)
parser.add_argument(
    "--combos-file", type=str, default=None,
    help="Path to a JSON file listing experiment combos (overrides built-in param grid)"
)
parser.add_argument(
    "--learning-rate", type=float, default=None,
    help="Default learning rate if not specified per combo"
)
args = parser.parse_args()

# =========================================
# ê³ ì •ëœ ë°˜ë³µ íšŸìˆ˜ ì„¤ì • (Syn ë°ì´í„°ì…‹ ì „ìš©)
# =========================================
SYN_REPETITIONS = 3  # secureXGB_syn_* ê³„ì—´ì„ ëª‡ ë²ˆ ë°˜ë³µí• ì§€

# =========================================
# Manual combo list (override via --combos-file)
# Each combo is a dict with keys:
#   dataset, method, max_bin, depth, n_estimators, learning_rate
# =========================================
manual_combos = [
    ## NDSS ì¶”ê°€ ì‹¤í—˜ (AUC)
    {"dataset":"processed_bank_marketing6","method":"sturges", "max_bin":8,  "depth":3, "n_estimators":15, "learning_rate":0.5},
    {"dataset":"processed_bank_marketing6","method":"sturges", "max_bin":8,  "depth":5, "n_estimators":15, "learning_rate":0.5},
    {"dataset":"processed_bank_marketing6","method":"sturges", "max_bin":6,  "depth":4, "n_estimators":15, "learning_rate":0.5},
    {"dataset":"processed_bank_marketing6","method":"sturges", "max_bin":10,  "depth":4, "n_estimators":15, "learning_rate":0.5},
    
    {"dataset":"default_of_credit_card","method":"sturges", "max_bin":8,  "depth":3, "n_estimators":15,  "learning_rate":0.5},
    {"dataset":"default_of_credit_card","method":"sturges", "max_bin":8,  "depth":5, "n_estimators":15,  "learning_rate":0.5},
    {"dataset":"default_of_credit_card","method":"sturges", "max_bin":6,  "depth":4, "n_estimators":15, "learning_rate":0.5},
    {"dataset":"default_of_credit_card","method":"sturges", "max_bin":10,  "depth":4, "n_estimators":15, "learning_rate":0.5},
    
    {"dataset":"processed_bank_marketing6","method":"sturges", "max_bin":8,  "depth":4, "n_estimators":20, "learning_rate":0.5},
    {"dataset":"default_of_credit_card","method":"sturges", "max_bin":8,  "depth":4, "n_estimators":20, "learning_rate":0.5},
    # {"dataset":"processed_bank_marketing6","method":"sturges", "max_bin":32,  "depth":4, "n_estimators":15, "learning_rate":0.5},
    # {"dataset":"default_of_credit_card","method":"sturges", "max_bin":32,  "depth":4, "n_estimators":15, "learning_rate":0.5},
    ##
    
    #### synthetic datasets
    ## (a)
    {"dataset":"secureXGB_syn_n30m50", "method":"sturges", "max_bin":8,  "depth":4, "n_estimators":15, "learning_rate":0.5},
    {"dataset":"secureXGB_syn_n70m50", "method":"sturges", "max_bin":8,  "depth":4, "n_estimators":15, "learning_rate":0.5},
    {"dataset":"secureXGB_syn_n50m30","method":"sturges", "max_bin":8,  "depth":4, "n_estimators":15, "learning_rate":0.5},
    {"dataset":"secureXGB_syn_n50m70","method":"sturges", "max_bin":8,  "depth":4, "n_estimators":15, "learning_rate":0.5},
    
    {"dataset":"secureXGB_syn_n50m50","method":"sturges", "max_bin":6,  "depth":4, "n_estimators":15, "learning_rate":0.5},
    {"dataset":"secureXGB_syn_n50m50","method":"sturges", "max_bin":10,  "depth":4, "n_estimators":15, "learning_rate":0.5},
    
    {"dataset":"secureXGB_syn_n50m50","method":"sturges", "max_bin":8,  "depth":3, "n_estimators":15, "learning_rate":0.5},
    {"dataset":"secureXGB_syn_n50m50","method":"sturges", "max_bin":8,  "depth":5, "n_estimators":15, "learning_rate":0.5},
    # ## (b)
    # {"dataset":"secureXGB_syn_n50m10","method":"sturges", "max_bin":8,  "depth":4, "n_estimators":15, "learning_rate":0.5},
    # {"dataset":"secureXGB_syn_n50m100","method":"sturges", "max_bin":8, "depth":4, "n_estimators":15, "learning_rate":0.5},
    # ## (c)
    # {"dataset":"secureXGB_syn_n50m50","method":"sturges", "max_bin":4,  "depth":4, "n_estimators":15, "learning_rate":0.5},
    # {"dataset":"secureXGB_syn_n50m50","method":"sturges", "max_bin":12, "depth":4, "n_estimators":15, "learning_rate":0.5},
    # {"dataset":"secureXGB_syn_n50m50","method":"sturges", "max_bin":6,  "depth":4, "n_estimators":15, "learning_rate":0.5},
    # {"dataset":"secureXGB_syn_n50m50","method":"sturges", "max_bin":10, "depth":4, "n_estimators":15, "learning_rate":0.5},
    # ## (d) ## ì¶”ê°€
    # {"dataset":"secureXGB_syn_n50m50","method":"sturges", "max_bin":8,  "depth":3, "n_estimators":15, "learning_rate":0.5},
    # {"dataset":"secureXGB_syn_n50m50","method":"sturges", "max_bin":8,  "depth":5, "n_estimators":15, "learning_rate":0.5},
    ### hqsfl synthetic datasets ## ì¶”ê°€ (CUDA OOM)
    # {"dataset":"hqsfl_syn3_40F","method":"sturges", "max_bin":30,  "depth":3, "n_estimators":10, "learning_rate":0.1},
    # {"dataset":"hqsfl_syn3_60F","method":"sturges", "max_bin":30,  "depth":3, "n_estimators":10, "learning_rate":0.1},
    # {"dataset":"hqsfl_syn3_80F","method":"sturges", "max_bin":30,  "depth":3, "n_estimators":10, "learning_rate":0.1},
    # {"dataset":"hqsfl_syn3_100F","method":"sturges", "max_bin":30,  "depth":3, "n_estimators":10, "learning_rate":0.1},
]

# combos ê°€ ë¹„ì–´ ìˆìœ¼ë©´ ì¢…ë£Œ
if not manual_combos:
    print("ğŸ›‘ No experiment combos found. Please fill 'manual_combos' or provide --combos-file.")
    exit(1)

# Paths and constants
data_base_path = "../data"
OUTPUT_BASE    = "./bin_results"
EXECUTABLE     = "../cpp_test/build/xgboost_cpp"
LOG_DIR        = "./logs"

os.makedirs(LOG_DIR, exist_ok=True)

# =========================================
# Main Loop
#   - secureXGB_syn_* ê³„ì—´ë§Œ SYN_REPETITIONS ë§Œí¼ ë°˜ë³µ
#   - bank_marketing / default_of_credit_card ê³„ì—´ì€ 5-foldë§Œ ì‹¤í–‰
# =========================================
for combo in manual_combos:
    dataset      = combo["dataset"]
    method       = combo.get("method", "sturges")
    max_bin      = combo["max_bin"]
    depth        = combo["depth"]
    n_estimators = combo["n_estimators"]
    lr           = combo.get("learning_rate", args.learning_rate)
    if lr is None:
        print(f"ğŸ›‘ Combo {combo} has no learning_rate and no default provided.")
        continue

    # ê³µí†µ ë””ë ‰í„°ë¦¬
    dataset_log_dir = os.path.join(LOG_DIR, dataset)
    os.makedirs(dataset_log_dir, exist_ok=True)
    base_name = f"{dataset}-{method}-b{max_bin}-d{depth}-t{n_estimators}-lr{lr}"

    # C++ binning ê²°ê³¼ê°€ ìˆì„ ê²½ë¡œ
    output_dir = os.path.join(OUTPUT_BASE, dataset, method)
    # bin_path   = os.path.join(output_dir, f"bin{max_bin}", "cutpoints.json")
    bin_path = os.path.join('./cpp_results',dataset,method, f"bin{max_bin}", "cutpoints.json") ## ìˆ˜ì •

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 1) â€œbank_marketingâ€ ë˜ëŠ” â€œdefault_of_credit_cardâ€ ê³„ì—´: 5-fold êµì°¨ê²€ì¦ë§Œ ì‹¤í–‰
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if dataset in ("bank_marketing", "default_of_credit_card", "processed_bank_marketing6"):
        # foldì€ 1~5 ê¹Œì§€
        for fold in range(1, 2):
            # ì„ì‹œ ë””ë ‰í† ë¦¬ (ê° foldì— ë§ì¶° train.csv/test.csv ë¡œ ì—°ê²°í•  ê³µê°„)
            temp_dir = f"./temp_run/{dataset}_fold{fold}/{method}"
            os.makedirs(temp_dir, exist_ok=True)

            # ì‹¤ì œ ì›ë³¸ì´ ì €ì¥ëœ ê²½ë¡œ: "../data/{dataset}/{method}/"
            src_plain_dir = os.path.join(data_base_path, dataset, method)
            src_train     = os.path.join(src_plain_dir, f"train{fold}.csv")
            src_test      = os.path.join(src_plain_dir, f"test{fold}.csv")

            # â”€â”€ ì„ì‹œ ë””ë ‰í† ë¦¬ì— train.csv / test.csv ë¡œ â€œë³µì‚¬â€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            tgt_train = os.path.join(temp_dir, "train.csv")
            tgt_test  = os.path.join(temp_dir, "test.csv")
            # ì´ë¯¸ ì¡´ì¬í•˜ë©´ ì‚­ì œ
            if os.path.exists(tgt_train):
                os.remove(tgt_train)
            if os.path.exists(tgt_test):
                os.remove(tgt_test)
            # ë³µì‚¬
            shutil.copy(src_train, tgt_train)
            shutil.copy(src_test,  tgt_test)

            # â”€â”€ run_only_train.py ì— ë„˜ê¸¸ ì¸ì â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            combo_data_base = f"./temp_run/{dataset}_fold{fold}"
            combo_dataset   = ""  # (run_only_train.py ë‚´ë¶€ì—ì„œ dataset=method/read_path ë¥¼ ë¹ˆ ë¬¸ìì—´ë¡œ ì²˜ë¦¬)

            # â”€â”€ ë¡œê·¸ íŒŒì¼ëª… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            dataset_log_dir = os.path.join(LOG_DIR, dataset)
            os.makedirs(dataset_log_dir, exist_ok=True)
            base_name = f"{dataset}-{method}-b{max_bin}-d{depth}-t{n_estimators}-lr{lr}"
            log_fname    = f"{base_name}-fold{fold}.log"
            log_filepath = os.path.join(dataset_log_dir, log_fname)

            with open(log_filepath, "w") as lf:
                def log(msg="", **kwargs):
                    print(msg, **kwargs)
                    print(msg, file=lf, **kwargs)

                log("========================================")
                log(f"ğŸš€ [{dataset}] Fold={fold} | bin={max_bin} | depth={depth} | trees={n_estimators} | lr={lr}")

                # 2-1) C++ binning
                print('bin_path:', bin_path)
                if not os.path.exists(bin_path):
                    log("â³ cutpoints.json ì—†ìŒ. C++ë¡œ binning ì‹¤í–‰...")
                    cmd_cpp = [
                        EXECUTABLE,
                        f"--dataset={dataset}/{method}",
                        f"--max_bins={max_bin}",
                        f"--depths={depth}",
                        f"--n_estimators={n_estimators}",
                        f"--output={OUTPUT_BASE}",
                    ]
                    t0 = time.perf_counter()
                    try:
                        subprocess.run(cmd_cpp, check=True)
                    except subprocess.CalledProcessError as e:
                        log(f"âŒ C++ binning ì‹¤íŒ¨ (code {e.returncode})")
                        cleanup_caches()
                        # ë³µì‚¬ëœ train/test íŒŒì¼ ì‚­ì œ
                        os.remove(tgt_train)
                        os.remove(tgt_test)
                        continue
                    log(f"âœ… C++ binning ì™„ë£Œ ({time.perf_counter() - t0:.2f}s)")
                else:
                    log("âœ… cutpoints.json ì¡´ì¬. C++ binning ë‹¨ê³„ ê±´ë„ˆëœ€")

                cleanup_caches()

                # 2-2) Python HE í•™ìŠµ/ì¶”ë¡ 
                log("â³ Python HE í•™ìŠµ/ì¶”ë¡  ì‹œì‘...")
                cmd_py = [
                    "python3", "../he/run_only_train.py",
                    # data_base_path ë¥¼ â€œ./temp_run/{dataset}_fold{fold}â€ ë¡œ ì§€ì •
                    "--data_base_path", combo_data_base,
                    "--dataset",        method,
                    "--method",         "",  
                    "--max_bins",       str(max_bin),
                    "--depths",         str(depth),
                    "--n_estimators",   str(n_estimators),
                    "--learning_rate",  str(lr),
                    "--bin_path",       bin_path,
                    "--save_path",      "./result",
                    "--log_path",       output_dir,
                ]
                t1 = time.perf_counter()
                try:
                    subprocess.run(cmd_py, stdout=lf, stderr=lf, check=True)
                except subprocess.CalledProcessError as e:
                    log(f"âŒ í•™ìŠµ/ì¶”ë¡  ì‹¤íŒ¨ (code {e.returncode})")
                    cleanup_caches()
                    # ë³µì‚¬ëœ train/test íŒŒì¼ ì‚­ì œ
                    os.remove(tgt_train)
                    os.remove(tgt_test)
                    continue
                log(f"âœ… í•™ìŠµ/ì¶”ë¡  ì™„ë£Œ ({time.perf_counter() - t1:.2f}s)")
                log("----------------------------------------\n")

            print(f"âš¡ ì™„ë£Œ: {base_name} | Fold={fold}")
            print(f"â–¶ ë¡œê·¸: {log_filepath}\n")

            # â”€â”€ í´ë“œë³„ ë³µì‚¬ëœ train/test íŒŒì¼ ì‚­ì œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            os.remove(tgt_train)
            os.remove(tgt_test)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 2) synthetic dataset: SYN_REPETITIONS ë§Œí¼ ë°˜ë³µ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    else:
        for rep in range(1, SYN_REPETITIONS + 1):
            log_fname    = f"{base_name}-run{rep}.log"
            log_filepath = os.path.join(dataset_log_dir, log_fname)

            with open(log_filepath, "w") as lf:
                def log(msg="", **kwargs):
                    print(msg, **kwargs)
                    print(msg, file=lf, **kwargs)

                log("========================================")
                log(f"ğŸš€ [{dataset}] | bin={max_bin} | depth={depth} | trees={n_estimators} | lr={lr} | run={rep}")

                # 1-1) C++ binning
                if not os.path.exists(bin_path):
                    log("â³ cutpoints.json ì—†ìŒ. C++ë¡œ binning ì‹¤í–‰...")
                    cmd_cpp = [
                        EXECUTABLE,
                        f"--dataset={dataset}/{method}",
                        f"--max_bins={max_bin}",
                        f"--depths={depth}",
                        f"--n_estimators={n_estimators}",
                        f"--output={OUTPUT_BASE}",
                    ]
                    t0 = time.perf_counter()
                    try:
                        subprocess.run(cmd_cpp, check=True)
                    except subprocess.CalledProcessError as e:
                        log(f"âŒ C++ binning ì‹¤íŒ¨ (code {e.returncode})")
                        cleanup_caches()
                        continue
                    log(f"âœ… C++ binning ì™„ë£Œ ({time.perf_counter() - t0:.2f}s)")
                else:
                    log("âœ… cutpoints.json ì¡´ì¬. C++ binning ë‹¨ê³„ ê±´ë„ˆëœ€")

                cleanup_caches()

                # 1-2) Python HE í•™ìŠµ/ì¶”ë¡ 
                log("â³ Python HE í•™ìŠµ/ì¶”ë¡  ì‹œì‘...")
                cmd_py = [
                    "python3", "../he/run_only_train.py",
                    "--data_base_path", data_base_path,
                    "--dataset",        dataset,
                    "--method",         method,
                    "--max_bins",       str(max_bin),
                    "--depths",         str(depth),
                    "--n_estimators",   str(n_estimators),
                    "--learning_rate",  str(lr),
                    "--bin_path",       bin_path,
                    "--save_path",      "./result",
                    "--log_path",       output_dir,
                ]
                t1 = time.perf_counter()
                try:
                    subprocess.run(cmd_py, stdout=lf, stderr=lf, check=True)
                except subprocess.CalledProcessError as e:
                    log(f"âŒ í•™ìŠµ/ì¶”ë¡  ì‹¤íŒ¨ (code {e.returncode})")
                    cleanup_caches()
                    continue

                log(f"âœ… í•™ìŠµ/ì¶”ë¡  ì™„ë£Œ ({time.perf_counter() - t1:.2f}s)")
                log("----------------------------------------\n")

            print(f"âš¡ ì™„ë£Œ: {base_name} | run={rep}")
            print(f"â–¶ ë¡œê·¸: {log_filepath}\n")
print("===== ëª¨ë“  ì‹¤í—˜ ì™„ë£Œ =====")
